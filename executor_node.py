import pandas as pd
import traceback
import os
from promptflow import tool

@tool
def execute_python_code(code: str):
    """
    Executes LLM-generated Python code against the Supply Chain dataset.
    
    :param code: The Python code string generated by the LLM.
    :param file_path: Path to the supply chain CSV file.
    :return: A string representation of the 'result' variable or an error message.
    """
    file_path = "data/DataCoSupplyChainDataset.csv"
    
    # 1. Clean the code input (Strip Markdown formatting)
    if not code:
        return "Error: No code provided by the LLM."
        
    if "```python" in code:
        code = code.split("```python")[1].split("```")[0].strip()
    elif "```" in code:
        code = code.split("```")[1].split("```")[0].strip()

    try:
        # 2. Load the Dataset
        # ISO-8859-1 encoding is standard for this specific dataset
        df = pd.read_csv(file_path, encoding='ISO-8859-1')
        
        # 3. Standardize Column Names
        # Matches the format: 'Delivery Status' -> 'Delivery_Status'
        # Matches the format: 'Days for shipping (real)' -> 'Days_for_shipping_real'
        df.columns = [
            col.replace(' ', '_')
               .replace('(', '')
               .replace(')', '')
               .replace('/', '_')
               .replace('-', '_')
            for col in df.columns
        ]
        
        # 4. Define the execution environment
        # We pass 'df' and 'pd' into the local context. 
        # We initialize 'result' to capture the output.
        local_vars = {
            'df': df, 
            'pd': pd, 
            'result': None
        }
        
        # 5. Execute the code
        # We use a copy of builtins for safety
        exec(code, {"__builtins__": __builtins__}, local_vars)
        
        # 6. Extract the 'result' variable populated by the LLM
        execution_output = local_vars.get('result')

        if execution_output is None:
            return (
                "Success: Code executed, but no 'result' was assigned. "
                "Ensure your prompt tells the model to assign the answer to the 'result' variable."
            )

        # 7. Format the output for the next node (Synthesis)
        if isinstance(execution_output, (pd.DataFrame, pd.Series)):
            # to_markdown() is highly recommended for LLM synthesis nodes. 
            # Note: requires 'tabulate' package installed in your environment.
            try:
                return execution_output.to_markdown()
            except ImportError:
                return execution_output.to_string()
        
        return str(execution_output)
        
    except Exception as e:
        # Return the full traceback so you can debug the LLM's logic in Prompt Flow
        error_type = type(e).__name__
        return f"Error during execution [{error_type}]: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"